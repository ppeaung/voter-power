import os
import csv 
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from scipy.stats import t
from scipy.special import erf


# ======================================================================
# GLOBAL VARIABLES 
# ======================================================================

YEAR = 2024
DAYS_UNTIL_ELECTION = (datetime(2024,11,5) - datetime.today()).days
SIGMA = 5

# Old one 
# SENATE_STATES = 'AZ,FL,MD,MI,MT,NV,OH,PA,TX,WI,WV '
SENATE_STATES = 'AZ,CA,CT,DE,FL,HI,IN,ME,MD,MA,MI,MN,MS,MO,MT,NE,NV,NJ,NM,NY,ND,OH,PA,RI,TN,TX,UT,VT,VA,WA,WV,WI,WY '

# ======================================================================
# HELPER FUNCTIONS
# ======================================================================


# Will this be the same as senate_median?
def EV_median(polls, bias_pct, num_states, dem_safe):
    """
    Args:
        - polls: Pandas dataframe containing scraped poll data
        - biaspct: Bias term
        - num_states: Number of states 
        - Demsafe: Number of confidently safe Senate Democratic seats 
        
    Returns: 
        various calculated values that correspond to their MATLAB counterparts
        Note that the tcdf function needs to be replaced with the appropriate Python function

    scipy.stats.t.cdf
    computes the cumulative distribution function (CDF) of the t-distribution
    
    x = np.array([-1, 0, 3, 4])  # Values at which to evaluate the CDF
    df = 10  # Degrees of freedom
    p = t.cdf(x, df)  # Compute the CDF

    print(p)
    # Output: [0.19146012 0.5        0.99330715 0.99864852]

    """

    # Working with pandas.DataFrame
    
    num_polls = polls['num_polls'] 
    # julian_date = polls[:, 1]
    # date_most_recent_poll = polls[:, 2]
    # median_margin = polls[:, 3]
    # est_std_dev = polls[:, 4]
    # state_num = polls[:, 5]

    # Calculate z-score and convert to probability, assuming normal distribution.
    #polls.z=(polls.margin+biaspct)./polls.SEM;
    #polls.prob_Dem_win=(erf(polls.z/sqrt(2))+1)/2;
    #polls.prob_GOP_win=1-polls.prob_Dem_win;
    #tateprobs=round(polls.prob_Dem_win*100);
    
    # Calculate z-score 
    polls['z'] = (polls['median margin'] + bias_pct) / polls['SEM']
    # Convert to probabilities 
 
    polls['prob_Dem_win'] = (erf(polls['z']/np.sqrt(2)) + 1)/2
    polls['prob_GOP_win'] = 1 - polls['prob_Dem_win']
    
    state_probs = np.round(polls['prob_DEM_win'] * 100)
    
    # Prob in November wasn't included in the original MATLAB script

    # The meta-magic: store the Electoral Votes (EV) distribution,
    # the exact probability distribution of all possible outcomes
    # Initialize a list to store the EV distribution
    EV_distribution = [1 - polls['prob_Dem_win'].iloc[0], polls['prob_Dem_win'].iloc[0]]
    for i in range(1, num_states):
        nextEV = [1 - polls['prob_Dem_win'].iloc[i], polls['prob_Dem_win'].iloc[i]]
        EV_distribution = np.convolve(EV_distribution, nextEV)
    
    print("Printing")
    print(EV_distribution)
    print("Done")

    # TODO: I think this is fine so far
    
    # Cumulative histogram of all possibilities
    # histogram=fliplr(EV_distribution(1:538)); %index of 1 for 1 EV...index of 538 for 538 EV
    # cumulative_prob=cumsum(histogram);
    # electoralvotes=1:538;

    # Calculate median and confidence bands from cumulative histogram
    # medianEV(1)=electoralvotes(min(find(cumulative_prob>=0.5)));  % 50-pct outcome
    
    

    # Cumulative histogram of all possibilities
    histogram = EV_distribution[1:num_states + 1]
    cumulative_prob = np.cumsum(histogram)

    print(histogram)

    # Range of Senate seats Democratics are projected to win
    senate_seats = range(dem_safe + 1, dem_safe + num_states + 1)
    print(senate_seats)
    R_Senate_control_probability = cumulative_prob[max(50 - dem_safe, 0)]
    D_Senate_control_probability = 1 - R_Senate_control_probability

    # Calculate Senate seat that represents the median of distribution of outcomes
    median_index = next(i for i, prob in enumerate(cumulative_prob) if prob >= 0.5)
    median_seats = senate_seats[median_index]

    # Calculate the mean number of expected Senate seats 
    weighted_seats = [histogram[i] * senate_seats[i] for i in range(len(histogram))]
    mean_seats = round(sum(weighted_seats), 2)

    print(mean_seats)

    return state_probs, state_nov_probs, histogram, cumulative_prob, R_Senate_control_probability, D_Senate_control_probability, median_seats, mean_seats

# ======================================================================
# LOAD POLL DATA
# ======================================================================

# Each state takes up 3 spaces
senate_csv_file_path = f'../outputs/{YEAR}.Senate.polls.median.csv'
senate_df = pd.read_csv(senate_csv_file_path)

num_states = len(SENATE_STATES) // 3
if senate_df.shape[0] % num_states !=0: 
    raise Exception(f"Warning: {YEAR}.Senate.polls.median.csv is not a multiple of num_states lines long") 

senate_df = senate_df.iloc[:num_states]

# TODO: Ask Sam about the implementation of analysisdate/search for it. As I see right now, there's no need
# to consider analysisdate (so do the loop where we only consider the first 1:numstates from the scraped polls)
# See the MATLAB script below

#% find the desired data within the file
#if analysisdate>0 && numlines>num_states
#    foo=find(polldata(:,2)==analysisdate,1,'first'); % find the start of the entry matching analysisdate
# %   ind=min([size(polldata,1)-num_states+1 foo']);
#    foo2=find(polldata(:,2)==max(polldata(:,5)),1,'first'); % find the start of the freshest entry
#    ind=max([foo2 foo]); %assume reverse time order, take whichever of the two was done earlier, also protect against no data for analysisdate
#    polldata=polldata(ind:ind+num_states-1,:);
#    clear foo2 foo ind
#elseif numlines>num_states
#%    polldata = polldata(numlines-num_states+1:numlines,:); % end of file
#    polldata = polldata(1:num_states,:); % top of file
#end

# Convert polls to statistics

# NOTE: May not need to convert to numpy array if we deal with Pandas df 

senate_margins = senate_df['median_margin'].to_numpy()

min_uncertainty = np.full(num_states, 3) # At least 2% uncertainty
senate_df['SEM'] = np.maximum(senate_df['median_std_dev'], min_uncertainty)
senate_sem = senate_df['SEM'].to_numpy()

total_polls_used = (senate_df['num_polls'].to_numpy()).sum()

# ======================================================================
# METAMARGIN CALCULATION
# ======================================================================

bias_pct = 0 # Where would this change? 
dem_safe = 42 # Number of safe Democratic seats for 2024

# Calculate needed statistics associated with Senate mean

(state_probs, state_nov_probs, histogram, cumulative_prob,
 R_Senate_control_probability, D_Senate_control_probability,
 median_seats, mean_seats) = Senate_median(senate_df, bias_pct, num_states, dem_safe)

reality = 1 - D_Senate_control_probability

meta_calc = 1

if meta_calc == 0: 
    metamargin = -999
else: 
    foo = bias_pct
    bias_pct = -7
    (state_probs, state_nov_probs, histogram, cumulative_prob,
    R_Senate_control_probability, D_Senate_control_probability,
    median_seats, mean_seats) = Senate_median(senate_df, bias_pct, num_states, dem_safe)
    while median_seats < 50: 
        bias_pct = bias_pct + 0.02
        (state_probs, state_nov_probs, histogram, cumulative_prob,
        R_Senate_control_probability, D_Senate_control_probability,
        median_seats, mean_seats) = Senate_median(senate_df, bias_pct, num_states, dem_safe)
    metamargin = -bias_pct
    bias_pct = foo
    del foo

# TODO: Test voter power calculation

# ======================================================================
# LOAD VOTER TURNOUT DATA
# ======================================================================
# Voter Turnout information

'AZ,CA,CT,DE,FL,HI,IN,ME,MD,MA,MI,MN,MS,MO,MT,NE,NV,NJ,NM,NY,ND,OH,PA,RI,TN,TX,UT,VT,VA,WA,WV,WI,WY '
vote_turnout = np.array([1424080,267040,2592310,914220,11146610,2540660,1297810,325630,205770,7796910,3964920,423440,595350,4144120,1880750,1230410,1008990,1502550,
                         1410460,680900,2031630,2511460,4500400,2526640,709100,2304250,468320,682710,1023610,626930,2645530,714750,5962270,3790200,242560,4201360,
                         1153280,1997680,5410020,361440,1718620,354670,1756390,8151590,1084630,291950,3021950,3067680,494750,2673150,198190])
# Old one
# vote_turnout = np.array([2592, 7797, 2031, 4500, 468, 1024, 4201, 5410, 8152, 2673, 495]) 

# TODO: Change csv file titles to align with variables (Unnamed -> ...)

# TODO: Read voter_turnout csv so that we only select the states of interest for the Senate instead of all 51 States

# vote_turnout_csv_file_path = './data/voter_turnout_data2022.csv'
# df = pd.read_csv(vote_turnout_csv_file_path)

# Extract state and turnout numbers
# vote_turnout_df = df[['State','Unnamed: 1']]
# vote_turnout_df =  vote_turnout_df.iloc[2:-1]

# Remove commas 
# vote_turnout_df['Unnamed: 1'] = vote_turnout_df['Unnamed: 1'].apply(lambda x: pd.to_numeric(x.replace(',', ''), errors='coerce'))
# vote_turnout_df['Unnamed: 1'] = pd.to_numeric(vote_turnout_df['Unnamed: 1'])

# Remove * 
# vote_turnout_df['State'] = vote_turnout_df['State'].apply(lambda x: x.replace('*', ''))

# For now, let's just look at the numbers 
# vote_turnout_dict = vote_turnout_df.to_dict(orient = "index")
# vote_turnout = vote_turnout_df['Unnamed: 1'].to_numpy()

# ======================================================================
# VOTER POWER CALCULATION
# ======================================================================

# t-pdf setup 
df = 3 
t_dist = t(df)

# For sanity checking
metamargin = 0 

Z = (senate_margins - metamargin) / SIGMA
num = t_dist.pdf(Z)
den = vote_turnout

voter_power = np.divide(num, den)
voter_power = ((voter_power - np.min(voter_power)) / (np.max(voter_power) - np.min(voter_power)))*100

# Hard-coded values for sanity check
# kvoters = np.array([2592, 7797, 2031, 4500, 468, 1024, 4201, 5410, 8152, 2673, 495]) 
# margins = np.array([3.0, -8.0, 5.0, 3.0, 0.0, 11.0, 8.0, 7.0, -11.0, 8.0, -33.0])

print(f"The metamargin is {metamargin}")
print(f"The voter power is {voter_power}")

# ======================================================================
# SAVE DATA 
# ======================================================================

# TODO: Get codes from geocodes csv file rather than hardcoding 

FIPS_Code = np.array([
    4, 6, 9, 10, 12, 15, 18, 23, 24, 25, 
    26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 
    38, 39, 42, 44, 47, 48, 49, 50, 51, 53, 
    54, 55, 56
])

State_Seats_List = np.array([
    "AZ", "CA", "CT", "DE", "FL", "HI", "IN", "ME", "MD", "MA", 
    "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NJ", "NM", "NY", 
    "ND", "OH", "PA", "RI", "TN", "TX", "UT", "VT", "VA", "WA", 
    "WV", "WI", "WY"
])
# Old one 
# FIPS_Code = np.array([4,12,24,26,30,32,39,42,48,55,54])
# Senate_Seats_List = np.array(['AZ','FL','MD','MI','MT','NV','OH','PA','TX','WI','WV'])

df = pd.DataFrame({
    'FIPS_CODE' : FIPS_Code, 
    'States' : Senate_Seats_List, 
    'Margins': senate_margins, 
    'Voter Power': voter_power
})

dir_path = os.path.dirname(os.path.realpath(__file__))

path = os.path.join(dir_path, f'outputs/{YEAR}.Senate.VoterPower.csv')
df.to_csv(path, index=False, float_format='%.2f')